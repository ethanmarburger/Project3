---
title: "Final Proejct: Modeling File"
format: html
editor: visual
---

```{r}
#| echo: false
#| include: false
library(tidymodels)
library(tidyverse)
library(ggplot2)
library(lubridate)
library(dplyr)
library(parsnip)
library(tune)
library(ggcorrplot)
library(tree)
library(baguette)
library(ranger)
library(rpart.plot)
library(yardstick)
```

## Introduction

### About the dataset:

The data for this project is from **Diabetes Health Indicators Dataset**. This dataset was put together from the Center of Disease Control's (CDC) Behavior Risk Factor Surveillance System (BRFSS) in 2015. The BRFSS is a premier telephone health-related telephone survey designed to collect state data about United States residents regarding their health-related risk behaviors, chronic health conditions, and use of preventive services. We are particularly interested in the indicators for Diabetes.

### Transformed variables from the dataset that we'll work with:

**diabetes**: If subject has diabetes or not. While the dataset source mentions a prediabetes level, there are no corresponding values in the dataset.

No Diabetes = no diabetes\
Diabetes = has diabetes

**high_bp**: If subject has high blood pressure or not.

No = no high blood pressure\
Yes = high blood pressure

**high_chol**: If subject has high cholesterol or not.

No = no high cholesterol\
Yes = high cholesterol

**BMI**: Body Mass Index.

**physical_act**: Physical activity in past 30 days - not including job.

No = no\
Yes = yes

**Sex**: Is the subject male or female.

Female = female\
Male = male

**Age**: Thirteen level category indicating the age of the subject.

Age Ranges\
18-24\
25-29\
30-34\
35-39\
40-44\
45-49\
50-54\
55-59\
60-64\
65-69\
70-74\
75-79\
80 or older

### Purpose of this File:

The goal of this file is to create models for predicting the diabetes variable. We'll be predicting this variable using Classification Tree and Random Forest models. To evaluate the our models, we'll use log-loss as our chosen metric. Additionally, we'll be using 5 fold cross-validation to select the best model from that family of models.

## Predictive Modeling Set up

```{r}
#| echo: true
#| include: false
# Reading in data and applying transformations for modeling
# Reading in Data
data_2 <- read_csv("diabetes_binary_health_indicators_BRFSS2015.csv")

# Selecting desired vairables
data_2 <- data_2 |>
  select(Diabetes_binary, HighBP, HighChol, BMI, PhysActivity, Sex, Age)

# Applying transformations to dataset
data_2 <- data_2 |>
  mutate(
    # Converting most variables to factors
    diabetes = as.factor(Diabetes_binary),
    high_bp = as.factor(HighBP),
    high_chol = as.factor(HighChol),
    physical_act = as.factor(PhysActivity),
    sex = as.factor(Sex),
    age = as.factor(Age),
    
    # Recoding factor levels to change the names of the values 
    diabetes = fct_recode(diabetes,
                          `No Diabetes` = "0",
                          Diabetes = "1"),
    high_bp = fct_recode(high_bp,
                         No = "0",
                         Yes = "1"),
    high_chol = fct_recode(high_chol,
                           No = "0",
                           Yes = "1"),
    physical_act = fct_recode(physical_act,
                              No = "0",
                              Yes = "1"),
    sex = fct_recode(sex,
                     Female = "0",
                     Male = "1"),
    age = fct_recode(age,
                     `18-24` = "1",
                     `25-29` = "2",
                     `30-34` = "3",
                     `35-39` = "4",
                     `40-44` = "5",
                     `45-49` = "6",
                     `50-54` = "7",
                     `55-59` = "8",
                     `60-64` = "9",
                     `65-69` = "10",
                     `70-74` = "11",
                     `75-79` = "12",
                     `80_or_older` = "13")) |>
  # Removing most original variables
  select(-Diabetes_binary, -HighBP, -HighChol, -PhysActivity, -Sex, -Age)
```

### Splitting Data into Training and Test Sets

```{r}
# Setting a seed to make things reproducible
set.seed(23)

# tidy models to split the data into a training and test set (70/30 split)
data_split <- initial_split(data_2, prop = 0.70, strata = diabetes)
data_train <- training(data_split)
data_test <- testing(data_split)

# 5 fold cross validation on the training set
data_5_fold <- vfold_cv(data_train, 5)
```

### Create our Recipe for Data Preprocessing

```{r}
rec <- recipe(diabetes ~ ., data = data_2) |>
  step_dummy(high_bp, high_chol, physical_act, sex, age) |>
  step_normalize(BMI)
```

## Fitting a tuned Classification Tree model

### What's a Classification Tree model?

Classification Trees are a type of decision tree model specifically designed for problems where the response variable is categorical, meaning it takes on discrete values, such as classes or labels. While similar in structure and approach to regression trees, which predict continuous numerical outcomes, classification trees aim to assign data points to specific categories based on the most prevalent class in a region.

### Creating a Classification Tree model instance

```{r}
class_tree_mod <- decision_tree(tree_depth = tune(), # Tuning parameters
                          min_n = 10,
                          cost_complexity = tune()) |>
  set_engine("rpart") |>
  set_mode("classification") # To classify the best predictor
```

### Classification Workflow

```{r}
class_tree_wkf <- workflow() |>
  add_recipe(rec) |>
  add_model(class_tree_mod)
```

### Fit Classification Model with tune_grid() and grid_regular()

```{r}
classification_grid <- class_tree_wkf |>
  tune_grid(resamples = data_5_fold,
            grid = grid_regular(tree_depth(), cost_complexity(), levels = 10),
            metrics = metric_set(mn_log_loss)) # Model metric
```

### Collecting the metrics computed across the folds for each tuning parameter

```{r}
classification_grid |>
  collect_metrics() |> # collecting defining model metrics
  filter(.metric == "mn_log_loss") # filter by defining model metrics
```

### Using select_best() to pull out best Classification model

```{r}
lowest_log_loss <- classification_grid |>
  select_best(metric = "mn_log_loss")
```

### fit best Classification Tree model to the entire training set to see the model fit

```{r}
classification_final_fit <- class_tree_wkf |>
  finalize_workflow(lowest_log_loss) |>
  last_fit(data_split, metrics = metric_set(mn_log_loss)) # defining model metrics

# Collecting full training set best model metrics 
classification_final_fit |>
  collect_metrics()
```

### Extracting the model fits for the best Classification Tree model

```{r}
# Extract the final model fits
classification_extract_final_model <- extract_workflow(classification_final_fit) 

# View extracted final model fit
classification_extract_final_model
```

## Fitting a tuned Random Forest model

### What's a Random Forest model?

Random Forest models are an ensemble learning technique that builds upon the idea of bagged (bootstrap aggregated) tree models. They are designed to improve prediction accuracy and robustness while reducing overfitting. Random Forest models achieve this by combining multiple decision trees trained on bootstrap samples of the data and introducing randomness in the predictor selection process at each split.

### Creating a Random Forest Instance

```{r}
rf_spec <- rand_forest(mtry = tune()) |> # varying values for mrty
 set_engine("ranger", importance = "impurity") |>
 set_mode("classification") # To classify best predictor
```

### Random Forest workflow

```{r}
rf_wkf <- workflow() |>
 add_recipe(rec) |> # Recipe
 add_model(rf_spec) # Defined model instance
```

### CV to Select our Tuning Parameters

```{r}
rf_fit <- rf_wkf |>
 tune_grid(resamples = data_5_fold,
 grid = 10,
 metrics = metric_set(mn_log_loss)) # defining model metrics
```

### Pulling out model metrics

```{r}
rf_fit |>
 collect_metrics() |> # Collecting defined model metrics
 filter(.metric == "mn_log_loss") |>
 arrange(mean) # Arranged by mean log-loss value
```

### Using select_best() to grab the best models tuning parameter values

```{r}
rf_best_params <- rf_fit |>
  select_best(metric = "mn_log_loss") # defining the metric
rf_best_params
```

### Finalizing our model on the training set by fitting this chosen model via finalize_workflow()

```{r}
rf_final_wkf <- rf_wkf |>
 finalize_workflow(rf_best_params)
```

### Fitting the best model to the entire training data set to test on the testing set

```{r}
rf_final_fit <- rf_final_wkf |>
 last_fit(data_split, metrics = metric_set(mn_log_loss)) # defining model metrics
rf_final_fit

rf_final_fit |>
  collect_metrics() # Collecting by defined model metrics
```

### Extracting the final model fit for the Random Forest model

```{r}
# final model fits
rf_final_model <- extract_fit_engine(rf_final_fit) 
rf_final_model
```

## Comparing Best Models fit to entire training set.

### Best Classification Tree Model

```{r}
classification_final_fit |>
  collect_metrics() # collecting defined model metrics
```

### Best Random Forest Model

```{r}
rf_final_fit |>
  collect_metrics() # Collecting by defined model metrics
```

### Which Model is the Best?

**Best model: Random Forest**

**The Random Forest model has a slightly better log-loss estimate of 0.335 while the Classification Tree model has a log-loss estimate of 0.349**
